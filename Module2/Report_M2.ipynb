{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Модуль Б**. Разработка модели машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импортирование библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модули для работы с моделью\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from Model.tokenizer import Tokenizer\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>record_duration</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>array</th>\n",
       "      <th>text_length</th>\n",
       "      <th>snr</th>\n",
       "      <th>rms_dB</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_ids</th>\n",
       "      <th>mel_spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...</td>\n",
       "      <td>Абай был не только талантливым поэтом, но и уч...</td>\n",
       "      <td>5.04</td>\n",
       "      <td>16000</td>\n",
       "      <td>[-1.0186341e-10, 6.91216e-11, -8.0035534e-11, ...</td>\n",
       "      <td>51</td>\n",
       "      <td>29.652618</td>\n",
       "      <td>-21.792862</td>\n",
       "      <td>[абай, _, был, _, не, _, только, _, талантливы...</td>\n",
       "      <td>[5165, 3734, 5298, 3734, 2808, 3734, 932, 3734...</td>\n",
       "      <td>[[-13.040601, -10.495326, -7.282387, -6.365622...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...</td>\n",
       "      <td>Гибкая кошка легко взбирается на высокое дерево.</td>\n",
       "      <td>5.65</td>\n",
       "      <td>16000</td>\n",
       "      <td>[2.910383e-11, -1.1641532e-10, 1.9645086e-10, ...</td>\n",
       "      <td>48</td>\n",
       "      <td>27.797586</td>\n",
       "      <td>-23.426945</td>\n",
       "      <td>[гибкая, _, кошка, _, легко, _, взбирается, _,...</td>\n",
       "      <td>[3706, 3734, 2332, 3734, 1692, 3734, 4548, 373...</td>\n",
       "      <td>[[-3.2210479, -4.417929, -6.569694, -5.2323184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...</td>\n",
       "      <td>Сделать нужно гораздо больше.</td>\n",
       "      <td>3.64</td>\n",
       "      <td>16000</td>\n",
       "      <td>[-1.3096724e-10, -5.820766e-11, -1.4551915e-10...</td>\n",
       "      <td>29</td>\n",
       "      <td>27.732599</td>\n",
       "      <td>-24.547728</td>\n",
       "      <td>[сделать, _, нужно, _, гораздо, _, больше]</td>\n",
       "      <td>[4891, 3734, 6461, 3734, 1353, 3734, 395]</td>\n",
       "      <td>[[-3.1968756, -3.3615067, -3.878891, -5.443349...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...</td>\n",
       "      <td>Эти ноты, сливаясь воедино, образуют симфонию,...</td>\n",
       "      <td>6.62</td>\n",
       "      <td>16000</td>\n",
       "      <td>[8.731149e-11, -6.91216e-11, 0.0, -8.0035534e-...</td>\n",
       "      <td>77</td>\n",
       "      <td>23.927074</td>\n",
       "      <td>-25.052473</td>\n",
       "      <td>[эти, _, ноты, _, сливаясь, _, воедино, _, обр...</td>\n",
       "      <td>[243, 3734, 5291, 3734, 3835, 3734, 3604, 3734...</td>\n",
       "      <td>[[-12.80517, -11.202806, -9.942759, -6.5413194...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...</td>\n",
       "      <td>Квадрат гипотенузы равен сумме квадратов катетов.</td>\n",
       "      <td>5.83</td>\n",
       "      <td>16000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>49</td>\n",
       "      <td>35.466934</td>\n",
       "      <td>-17.979994</td>\n",
       "      <td>[квадрат, _, гипотенузы, _, равен, _, сумме, _...</td>\n",
       "      <td>[5016, 3734, 3892, 3734, 4864, 3734, 4855, 373...</td>\n",
       "      <td>[[-5.968595, -4.914544, -4.8844056, -4.73808, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...   \n",
       "1  Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...   \n",
       "2  Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...   \n",
       "3  Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...   \n",
       "4  Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...   \n",
       "\n",
       "                                            sentence  record_duration  \\\n",
       "0  Абай был не только талантливым поэтом, но и уч...             5.04   \n",
       "1   Гибкая кошка легко взбирается на высокое дерево.             5.65   \n",
       "2                      Сделать нужно гораздо больше.             3.64   \n",
       "3  Эти ноты, сливаясь воедино, образуют симфонию,...             6.62   \n",
       "4  Квадрат гипотенузы равен сумме квадратов катетов.             5.83   \n",
       "\n",
       "   sampling_rate                                              array  \\\n",
       "0          16000  [-1.0186341e-10, 6.91216e-11, -8.0035534e-11, ...   \n",
       "1          16000  [2.910383e-11, -1.1641532e-10, 1.9645086e-10, ...   \n",
       "2          16000  [-1.3096724e-10, -5.820766e-11, -1.4551915e-10...   \n",
       "3          16000  [8.731149e-11, -6.91216e-11, 0.0, -8.0035534e-...   \n",
       "4          16000  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "   text_length        snr     rms_dB  \\\n",
       "0           51  29.652618 -21.792862   \n",
       "1           48  27.797586 -23.426945   \n",
       "2           29  27.732599 -24.547728   \n",
       "3           77  23.927074 -25.052473   \n",
       "4           49  35.466934 -17.979994   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [абай, _, был, _, не, _, только, _, талантливы...   \n",
       "1  [гибкая, _, кошка, _, легко, _, взбирается, _,...   \n",
       "2         [сделать, _, нужно, _, гораздо, _, больше]   \n",
       "3  [эти, _, ноты, _, сливаясь, _, воедино, _, обр...   \n",
       "4  [квадрат, _, гипотенузы, _, равен, _, сумме, _...   \n",
       "\n",
       "                                           token_ids  \\\n",
       "0  [5165, 3734, 5298, 3734, 2808, 3734, 932, 3734...   \n",
       "1  [3706, 3734, 2332, 3734, 1692, 3734, 4548, 373...   \n",
       "2          [4891, 3734, 6461, 3734, 1353, 3734, 395]   \n",
       "3  [243, 3734, 5291, 3734, 3835, 3734, 3604, 3734...   \n",
       "4  [5016, 3734, 3892, 3734, 4864, 3734, 4855, 373...   \n",
       "\n",
       "                                            mel_spec  \n",
       "0  [[-13.040601, -10.495326, -7.282387, -6.365622...  \n",
       "1  [[-3.2210479, -4.417929, -6.569694, -5.2323184...  \n",
       "2  [[-3.1968756, -3.3615067, -3.878891, -5.443349...  \n",
       "3  [[-12.80517, -11.202806, -9.942759, -6.5413194...  \n",
       "4  [[-5.968595, -4.914544, -4.8844056, -4.73808, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# путь к обработанным данным\n",
    "df_path = '../Module1/Dataset/dataset.h5'\n",
    "# загружаем датасета\n",
    "df = pd.read_hdf(df_path, key='df')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Европейский союз будет оставаться наблюдателем в Генеральной Ассамблее.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example = df['sentence'][42]\n",
    "text_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Класс с моделью**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, nhead=4),\n",
    "            num_layers=3\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(d_model, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 80)  # n_mels = 80\n",
    "        )\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        x = self.embedding(tokens)\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSDataset(Dataset):\n",
    "    def __init__(self, tokenized_texts, mel_spectrograms, \n",
    "                 pad_token_id=0, mel_pad_value=-100):\n",
    "        \"\"\"\n",
    "        Улучшенная версия датасета с тщательной проверкой размерностей\n",
    "        \n",
    "        Args:\n",
    "            tokenized_texts: список списков int (токены)\n",
    "            mel_spectrograms: список np.array формы (time, n_mels)\n",
    "            pad_token_id: ID для паддинга текста\n",
    "            mel_pad_value: значение для паддинга спектрограмм\n",
    "        \"\"\"\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "        self.mel_spectrograms = mel_spectrograms\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.mel_pad_value = mel_pad_value\n",
    "        \n",
    "        # Проверка согласованности данных\n",
    "        self._validate_data()\n",
    "        \n",
    "        # Запоминаем размерность мел-признаков\n",
    "        self.n_mels = mel_spectrograms[0].shape[1]\n",
    "\n",
    "    def _validate_data(self):\n",
    "        assert len(self.tokenized_texts) == len(self.mel_spectrograms), \\\n",
    "            f\"Несовпадение количества текстов ({len(self.tokenized_texts)}) и спектрограмм ({len(self.mel_spectrograms)})\"\n",
    "        \n",
    "        # Проверяем что все спектрограммы 2D и имеют одинаковое n_mels\n",
    "        n_mels = self.mel_spectrograms[0].shape[1]\n",
    "        for i, mel in enumerate(self.mel_spectrograms):\n",
    "            assert mel.ndim == 2, f\"Спектрограмма {i} должна быть 2D, но имеет {mel.ndim} измерений\"\n",
    "            assert mel.shape[1] == n_mels, \\\n",
    "                f\"Несовпадение n_mels: ожидается {n_mels}, получено {mel.shape[1]} в спектрограмме {i}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Возвращаем тензоры напрямую\n",
    "        return (\n",
    "            torch.LongTensor(self.tokenized_texts[idx]),\n",
    "            torch.FloatTensor(self.mel_spectrograms[idx])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Улучшенная функция для создания батчей с паддингом\"\"\"\n",
    "    tokens, mels = zip(*batch)\n",
    "    \n",
    "    # 1. Паддинг токенов\n",
    "    tokens_padded = pad_sequence(\n",
    "        tokens, \n",
    "        batch_first=True, \n",
    "        padding_value=0\n",
    "    )\n",
    "    \n",
    "    # 2. Паддинг спектрограмм\n",
    "    # Находим максимальную длину в батче\n",
    "    max_len = max(mel.size(0) for mel in mels)\n",
    "    n_mels = mels[0].size(1)\n",
    "    \n",
    "    # Создаем большой тензор с паддингом\n",
    "    mels_padded = torch.full(\n",
    "        (len(mels), max_len, n_mels),\n",
    "        fill_value=-100,\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    \n",
    "    # Заполняем данные без ошибок размерностей\n",
    "    for i, mel in enumerate(mels):\n",
    "        actual_len = mel.size(0)\n",
    "        mels_padded[i, :actual_len, :] = mel  # Точно соответствуем размерностям\n",
    "    \n",
    "    return tokens_padded, mels_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = df['token_ids']\n",
    "mel_spectrograms = df['mel_spec']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при создании датасета: Несовпадение n_mels: ожидается 177, получено 183 в спектрограмме 1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Несовпадение n_mels: ожидается 177, получено 183 в спектрограмме 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[96]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Создаем и проверяем датасет\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     dataset = \u001b[43mTTSDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_spectrograms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mДатасет создан успешно!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Проверяем один пример\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mTTSDataset.__init__\u001b[39m\u001b[34m(self, tokenized_texts, mel_spectrograms, pad_token_id, mel_pad_value)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mself\u001b[39m.mel_pad_value = mel_pad_value\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Проверка согласованности данных\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Запоминаем размерность мел-признаков\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m.n_mels = mel_spectrograms[\u001b[32m0\u001b[39m].shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mTTSDataset._validate_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, mel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.mel_spectrograms):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m mel.ndim == \u001b[32m2\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mСпектрограмма \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m должна быть 2D, но имеет \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmel.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m измерений\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m mel.shape[\u001b[32m1\u001b[39m] == n_mels, \\\n\u001b[32m     33\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mНесовпадение n_mels: ожидается \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_mels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, получено \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmel.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m в спектрограмме \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Несовпадение n_mels: ожидается 177, получено 183 в спектрограмме 1"
     ]
    }
   ],
   "source": [
    "# Создаем и проверяем датасет\n",
    "try:\n",
    "    dataset = TTSDataset(tokenized_texts, mel_spectrograms)\n",
    "    print(\"Датасет создан успешно!\")\n",
    "    \n",
    "    # Проверяем один пример\n",
    "    tokens, mel = dataset[1]\n",
    "    print(\"\\nПример 1:\")\n",
    "    print(f\"Токены: {tokens.shape} (макс: {tokens.max().item()})\")\n",
    "    print(f\"Спектрограмма: {mel.shape} (макс: {mel.max().item():.2f})\")\n",
    "    \n",
    "    # Создаем DataLoader с обработкой ошибок\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=0  # Для лучшей отладки\n",
    "    )\n",
    "    \n",
    "    # Тестируем батчи\n",
    "    for batch_idx, (tokens_batch, mels_batch) in enumerate(dataloader):\n",
    "        print(f\"\\nБатч {batch_idx}:\")\n",
    "        print(f\"Токены: {tokens_batch.shape}\")\n",
    "        print(f\"Спектрограммы: {mels_batch.shape}\")\n",
    "        print(f\"Реальные длины: {[mel.size(0) for mel in mels]}\")\n",
    "        break\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при создании датасета: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример 0:\n",
      "Токены: tensor([5165, 3734, 5298, 3734, 2808, 3734,  932, 3734,  460, 3734, 5910, 3734,\n",
      "        4008, 3734, 4773, 3734, 1197]) (длина: 17)\n",
      "Спектрограмма: torch.Size([80, 177])\n"
     ]
    }
   ],
   "source": [
    "# Проверяем один пример\n",
    "tokens, mel = dataset[0]\n",
    "print(\"Пример 0:\")\n",
    "print(f\"Токены: {tokens} (длина: {len(tokens)})\")\n",
    "print(f\"Спектрограмма: {mel.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataLoader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (129) must match the existing size (147) at non-singleton dimension 1.  Target sizes: [80, 129].  Tensor sizes: [80, 147]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[99]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Проверяем батч\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmels_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mБатч \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mТокены: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtokens_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mcollate_fn\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, mel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(mels):\n\u001b[32m     26\u001b[39m     actual_len = mel.size(\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mmels_padded\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mactual_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m = mel  \u001b[38;5;66;03m# Точно соответствуем размерностям\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokens_padded, mels_padded\n",
      "\u001b[31mRuntimeError\u001b[39m: The expanded size of the tensor (129) must match the existing size (147) at non-singleton dimension 1.  Target sizes: [80, 129].  Tensor sizes: [80, 147]"
     ]
    }
   ],
   "source": [
    "# Проверяем батч\n",
    "for batch_idx, (tokens_batch, mels_batch) in enumerate(dataloader):\n",
    "    print(f\"\\nБатч {batch_idx}:\")\n",
    "    print(f\"Токены: {tokens_batch.shape}\")\n",
    "    print(f\"Спектрограммы: {mels_batch.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Chemp/Speech-synthesis/Module2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (217) must match the size of tensor b (213) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=\u001b[32m1e-4\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpred_mels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mcollate_fn\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m      8\u001b[39m tokens_padded = pad_sequence(\n\u001b[32m      9\u001b[39m     [torch.LongTensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens],\n\u001b[32m     10\u001b[39m     batch_first=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     11\u001b[39m     padding_value=\u001b[32m6674\u001b[39m  \u001b[38;5;66;03m# id токена <pad>\u001b[39;00m\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Паддинг спектрограмм (добиваем -100 или нулями)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m mels_padded = \u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Для ignore_loss в модели\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokens_padded, mels_padded\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/nn/utils/rnn.py:481\u001b[39m, in \u001b[36mpad_sequence\u001b[39m\u001b[34m(sequences, batch_first, padding_value, padding_side)\u001b[39m\n\u001b[32m    477\u001b[39m         sequences = sequences.unbind(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    483\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (217) must match the size of tensor b (213) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model = TTSTransformer(vocab_size=len(tokenizer.text_to_ids_voc))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for tokens, mels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred_mels = model(tokens)\n",
    "        loss = criterion(pred_mels, mels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
