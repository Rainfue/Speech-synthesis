{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Модуль Б**. Разработка модели машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импортирование библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модули для работы с моделью\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from Model.tokenizer import Tokenizer\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>record_duration</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>array</th>\n",
       "      <th>text_length</th>\n",
       "      <th>snr</th>\n",
       "      <th>rms_dB</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_ids</th>\n",
       "      <th>mel_spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...</td>\n",
       "      <td>Абай был не только талантливым поэтом, но и уч...</td>\n",
       "      <td>5.04</td>\n",
       "      <td>16000</td>\n",
       "      <td>[-1.0186341e-10, 6.91216e-11, -8.0035534e-11, ...</td>\n",
       "      <td>51</td>\n",
       "      <td>29.652618</td>\n",
       "      <td>-21.792862</td>\n",
       "      <td>[абай, _, был, _, не, _, только, _, талантливы...</td>\n",
       "      <td>[5165, 3734, 5298, 3734, 2808, 3734, 932, 3734...</td>\n",
       "      <td>[[-13.040601, -10.495326, -7.282387, -6.365622...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...</td>\n",
       "      <td>Гибкая кошка легко взбирается на высокое дерево.</td>\n",
       "      <td>5.65</td>\n",
       "      <td>16000</td>\n",
       "      <td>[2.910383e-11, -1.1641532e-10, 1.9645086e-10, ...</td>\n",
       "      <td>48</td>\n",
       "      <td>27.797586</td>\n",
       "      <td>-23.426945</td>\n",
       "      <td>[гибкая, _, кошка, _, легко, _, взбирается, _,...</td>\n",
       "      <td>[3706, 3734, 2332, 3734, 1692, 3734, 4548, 373...</td>\n",
       "      <td>[[-3.2210479, -4.417929, -6.569694, -5.2323184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...</td>\n",
       "      <td>Сделать нужно гораздо больше.</td>\n",
       "      <td>3.64</td>\n",
       "      <td>16000</td>\n",
       "      <td>[-1.3096724e-10, -5.820766e-11, -1.4551915e-10...</td>\n",
       "      <td>29</td>\n",
       "      <td>27.732599</td>\n",
       "      <td>-24.547728</td>\n",
       "      <td>[сделать, _, нужно, _, гораздо, _, больше]</td>\n",
       "      <td>[4891, 3734, 6461, 3734, 1353, 3734, 395, 6674...</td>\n",
       "      <td>[[-3.1968756, -3.3615067, -3.878891, -5.443349...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...</td>\n",
       "      <td>Эти ноты, сливаясь воедино, образуют симфонию,...</td>\n",
       "      <td>6.62</td>\n",
       "      <td>16000</td>\n",
       "      <td>[8.731149e-11, -6.91216e-11, 0.0, -8.0035534e-...</td>\n",
       "      <td>77</td>\n",
       "      <td>23.927074</td>\n",
       "      <td>-25.052473</td>\n",
       "      <td>[эти, _, ноты, _, сливаясь, _, воедино, _, обр...</td>\n",
       "      <td>[243, 3734, 5291, 3734, 3835, 3734, 3604, 3734...</td>\n",
       "      <td>[[-12.80517, -11.202806, -9.942759, -6.5413194...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...</td>\n",
       "      <td>Квадрат гипотенузы равен сумме квадратов катетов.</td>\n",
       "      <td>5.83</td>\n",
       "      <td>16000</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>49</td>\n",
       "      <td>35.466934</td>\n",
       "      <td>-17.979994</td>\n",
       "      <td>[квадрат, _, гипотенузы, _, равен, _, сумме, _...</td>\n",
       "      <td>[5016, 3734, 3892, 3734, 4864, 3734, 4855, 373...</td>\n",
       "      <td>[[-5.968595, -4.914544, -4.8844056, -4.73808, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...   \n",
       "1  Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...   \n",
       "2  Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...   \n",
       "3  Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...   \n",
       "4  Data/cv_corpus/cv-corpus-21.0-delta-2025-03-14...   \n",
       "\n",
       "                                            sentence  record_duration  \\\n",
       "0  Абай был не только талантливым поэтом, но и уч...             5.04   \n",
       "1   Гибкая кошка легко взбирается на высокое дерево.             5.65   \n",
       "2                      Сделать нужно гораздо больше.             3.64   \n",
       "3  Эти ноты, сливаясь воедино, образуют симфонию,...             6.62   \n",
       "4  Квадрат гипотенузы равен сумме квадратов катетов.             5.83   \n",
       "\n",
       "   sampling_rate                                              array  \\\n",
       "0          16000  [-1.0186341e-10, 6.91216e-11, -8.0035534e-11, ...   \n",
       "1          16000  [2.910383e-11, -1.1641532e-10, 1.9645086e-10, ...   \n",
       "2          16000  [-1.3096724e-10, -5.820766e-11, -1.4551915e-10...   \n",
       "3          16000  [8.731149e-11, -6.91216e-11, 0.0, -8.0035534e-...   \n",
       "4          16000  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "   text_length        snr     rms_dB  \\\n",
       "0           51  29.652618 -21.792862   \n",
       "1           48  27.797586 -23.426945   \n",
       "2           29  27.732599 -24.547728   \n",
       "3           77  23.927074 -25.052473   \n",
       "4           49  35.466934 -17.979994   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [абай, _, был, _, не, _, только, _, талантливы...   \n",
       "1  [гибкая, _, кошка, _, легко, _, взбирается, _,...   \n",
       "2         [сделать, _, нужно, _, гораздо, _, больше]   \n",
       "3  [эти, _, ноты, _, сливаясь, _, воедино, _, обр...   \n",
       "4  [квадрат, _, гипотенузы, _, равен, _, сумме, _...   \n",
       "\n",
       "                                           token_ids  \\\n",
       "0  [5165, 3734, 5298, 3734, 2808, 3734, 932, 3734...   \n",
       "1  [3706, 3734, 2332, 3734, 1692, 3734, 4548, 373...   \n",
       "2  [4891, 3734, 6461, 3734, 1353, 3734, 395, 6674...   \n",
       "3  [243, 3734, 5291, 3734, 3835, 3734, 3604, 3734...   \n",
       "4  [5016, 3734, 3892, 3734, 4864, 3734, 4855, 373...   \n",
       "\n",
       "                                            mel_spec  \n",
       "0  [[-13.040601, -10.495326, -7.282387, -6.365622...  \n",
       "1  [[-3.2210479, -4.417929, -6.569694, -5.2323184...  \n",
       "2  [[-3.1968756, -3.3615067, -3.878891, -5.443349...  \n",
       "3  [[-12.80517, -11.202806, -9.942759, -6.5413194...  \n",
       "4  [[-5.968595, -4.914544, -4.8844056, -4.73808, ...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# путь к обработанным данным\n",
    "df_path = '../Module1/Dataset/dataset.h5'\n",
    "# загружаем датасета\n",
    "df = pd.read_hdf(df_path, key='df')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Европейский союз будет оставаться наблюдателем в Генеральной Ассамблее.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example = df['sentence'][42]\n",
    "text_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Класс с моделью**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, nhead=4),\n",
    "            num_layers=3\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(d_model, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 429)  # n_mels = 429\n",
    "        )\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        x = self.embedding(tokens)\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSDataset(Dataset):\n",
    "    def __init__(self, tokenized_texts, mel_spectrograms, \n",
    "                 pad_token_id=0, mel_pad_value=-100):\n",
    "        \"\"\"\n",
    "        Улучшенная версия датасета с тщательной проверкой размерностей\n",
    "        \n",
    "        Args:\n",
    "            tokenized_texts: список списков int (токены)\n",
    "            mel_spectrograms: список np.array формы (time, n_mels)\n",
    "            pad_token_id: ID для паддинга текста\n",
    "            mel_pad_value: значение для паддинга спектрограмм\n",
    "        \"\"\"\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "        self.mel_spectrograms = mel_spectrograms\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.mel_pad_value = mel_pad_value\n",
    "        \n",
    "        # Проверка согласованности данных\n",
    "        self._validate_data()\n",
    "        \n",
    "        # Запоминаем размерность мел-признаков\n",
    "        self.n_mels = mel_spectrograms[0].shape[1]\n",
    "\n",
    "    def _validate_data(self):\n",
    "        assert len(self.tokenized_texts) == len(self.mel_spectrograms), \\\n",
    "            f\"Несовпадение количества текстов ({len(self.tokenized_texts)}) и спектрограмм ({len(self.mel_spectrograms)})\"\n",
    "        \n",
    "        # Проверяем что все спектрограммы 2D и имеют одинаковое n_mels\n",
    "        n_mels = self.mel_spectrograms[0].shape[1]\n",
    "        for i, mel in enumerate(self.mel_spectrograms):\n",
    "            assert mel.ndim == 2, f\"Спектрограмма {i} должна быть 2D, но имеет {mel.ndim} измерений\"\n",
    "            assert mel.shape[1] == n_mels, \\\n",
    "                f\"Несовпадение n_mels: ожидается {n_mels}, получено {mel.shape[1]} в спектрограмме {i}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Возвращаем тензоры напрямую\n",
    "        return (\n",
    "            torch.LongTensor(self.tokenized_texts[idx]),\n",
    "            torch.FloatTensor(self.mel_spectrograms[idx])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Улучшенная функция для создания батчей с паддингом\"\"\"\n",
    "    tokens, mels = zip(*batch)\n",
    "    \n",
    "    # 1. Паддинг токенов\n",
    "    tokens_padded = pad_sequence(\n",
    "        tokens, \n",
    "        batch_first=True, \n",
    "        padding_value=0\n",
    "    )\n",
    "    \n",
    "    # 2. Паддинг спектрограмм\n",
    "    # Находим максимальную длину в батче\n",
    "    max_len = max(mel.size(0) for mel in mels)\n",
    "    n_mels = mels[0].size(1)\n",
    "    \n",
    "    # Создаем большой тензор с паддингом\n",
    "    mels_padded = torch.full(\n",
    "        (len(mels), max_len, n_mels),\n",
    "        fill_value=-100,\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    \n",
    "    # Заполняем данные без ошибок размерностей\n",
    "    for i, mel in enumerate(mels):\n",
    "        actual_len = mel.size(0)\n",
    "        mels_padded[i, :actual_len, :] = mel  # Точно соответствуем размерностям\n",
    "    \n",
    "    return tokens_padded, mels_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = df['token_ids']\n",
    "mel_spectrograms = df['mel_spec']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет создан успешно!\n",
      "\n",
      "Пример 1:\n",
      "Токены: torch.Size([27]) (макс: 6674)\n",
      "Спектрограмма: torch.Size([80, 429]) (макс: 6.52)\n",
      "\n",
      "Батч 0:\n",
      "Токены: torch.Size([2, 27])\n",
      "Спектрограммы: torch.Size([2, 80, 429])\n",
      "Ошибка при создании датасета: name 'mels' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mТокены: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokens_batch.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mСпектрограммы: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmels_batch.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mРеальные длины: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[mel.size(\u001b[32m0\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mmel\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[43mmels\u001b[49m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mNameError\u001b[39m: name 'mels' is not defined"
     ]
    }
   ],
   "source": [
    "# Создаем и проверяем датасет\n",
    "try:\n",
    "    dataset = TTSDataset(tokenized_texts, mel_spectrograms)\n",
    "    print(\"Датасет создан успешно!\")\n",
    "    \n",
    "    # Проверяем один пример\n",
    "    tokens, mel = dataset[1]\n",
    "    print(\"\\nПример 1:\")\n",
    "    print(f\"Токены: {tokens.shape} (макс: {tokens.max().item()})\")\n",
    "    print(f\"Спектрограмма: {mel.shape} (макс: {mel.max().item():.2f})\")\n",
    "    \n",
    "    # Создаем DataLoader с обработкой ошибок\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=0  # Для лучшей отладки\n",
    "    )\n",
    "    \n",
    "    # Тестируем батчи\n",
    "    for batch_idx, (tokens_batch, mels_batch) in enumerate(dataloader):\n",
    "        print(f\"\\nБатч {batch_idx}:\")\n",
    "        print(f\"Токены: {tokens_batch.shape}\")\n",
    "        print(f\"Спектрограммы: {mels_batch.shape}\")\n",
    "        print(f\"Реальные длины: {[mel.size(0) for mel in mels]}\")\n",
    "        break\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при создании датасета: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример 0:\n",
      "Токены: tensor([5165, 3734, 5298, 3734, 2808, 3734,  932, 3734,  460, 3734, 5910, 3734,\n",
      "        4008, 3734, 4773, 3734, 1197, 6674, 6674, 6674, 6674, 6674, 6674, 6674,\n",
      "        6674, 6674, 6674]) (длина: 27)\n",
      "Спектрограмма: torch.Size([80, 429])\n"
     ]
    }
   ],
   "source": [
    "# Проверяем один пример\n",
    "tokens, mel = dataset[0]\n",
    "print(\"Пример 0:\")\n",
    "print(f\"Токены: {tokens} (длина: {len(tokens)})\")\n",
    "print(f\"Спектрограмма: {mel.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataLoader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Батч 0:\n",
      "Токены: torch.Size([2, 27])\n",
      "Спектрограммы: torch.Size([2, 80, 429])\n"
     ]
    }
   ],
   "source": [
    "# Проверяем батч\n",
    "for batch_idx, (tokens_batch, mels_batch) in enumerate(dataloader):\n",
    "    print(f\"\\nБатч {batch_idx}:\")\n",
    "    print(f\"Токены: {tokens_batch.shape}\")\n",
    "    print(f\"Спектрограммы: {mels_batch.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Chemp/Speech-synthesis/Module2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Chemp/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "/home/user/Chemp/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([2, 80, 429])) that is different to the input size (torch.Size([2, 27, 80])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (80) must match the size of tensor b (429) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[112]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m optimizer.zero_grad()\n\u001b[32m      8\u001b[39m pred_mels = model(tokens)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m loss.backward()\n\u001b[32m     11\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610\u001b[39m, in \u001b[36mMSELoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/nn/functional.py:3884\u001b[39m, in \u001b[36mmse_loss\u001b[39m\u001b[34m(input, target, size_average, reduce, reduction, weight)\u001b[39m\n\u001b[32m   3881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3882\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3884\u001b[39m expanded_input, expanded_target = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3887\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m weight.size() != \u001b[38;5;28minput\u001b[39m.size():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Chemp/.venv/lib/python3.12/site-packages/torch/functional.py:76\u001b[39m, in \u001b[36mbroadcast_tensors\u001b[39m\u001b[34m(*tensors)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, *tensors)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (80) must match the size of tensor b (429) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "model = TTSTransformer(vocab_size=len(tokenizer.text_to_ids_voc))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for tokens, mels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred_mels = model(tokens)\n",
    "        loss = criterion(pred_mels, mels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
