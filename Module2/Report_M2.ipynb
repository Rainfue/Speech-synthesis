{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Модуль Б**. Разработка модели машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импортирование библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модули для работы с моделью\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from Model.tokenizer import Tokenizer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm  # Импортируем tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_ids</th>\n",
       "      <th>mel_spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[25, 8, 25, 4, 3, 8, 5, 13, 3, 15, 10, 3, 11, ...</td>\n",
       "      <td>[[-56.18891, -54.528297, -43.84198, -44.330162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[21, 9, 8, 12, 25, 20, 3, 12, 2, 24, 12, 25, 3...</td>\n",
       "      <td>[[-55.704872, -55.704872, -55.704872, -55.7048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[22, 28, 10, 13, 25, 11, 0, 3, 15, 23, 18, 15,...</td>\n",
       "      <td>[[-57.897354, -57.897354, -51.308334, -54.8423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[14, 11, 9, 3, 15, 2, 11, 5, 3, 22, 13, 9, 19,...</td>\n",
       "      <td>[[-59.127876, -59.127876, -55.668625, -55.1438...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[12, 19, 25, 28, 6, 25, 11, 3, 21, 9, 32, 2, 1...</td>\n",
       "      <td>[[-50.631554, -50.631554, -50.631554, -50.6315...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           token_ids  \\\n",
       "0  [25, 8, 25, 4, 3, 8, 5, 13, 3, 15, 10, 3, 11, ...   \n",
       "1  [21, 9, 8, 12, 25, 20, 3, 12, 2, 24, 12, 25, 3...   \n",
       "2  [22, 28, 10, 13, 25, 11, 0, 3, 15, 23, 18, 15,...   \n",
       "3  [14, 11, 9, 3, 15, 2, 11, 5, 3, 22, 13, 9, 19,...   \n",
       "4  [12, 19, 25, 28, 6, 25, 11, 3, 21, 9, 32, 2, 1...   \n",
       "\n",
       "                                            mel_spec  \n",
       "0  [[-56.18891, -54.528297, -43.84198, -44.330162...  \n",
       "1  [[-55.704872, -55.704872, -55.704872, -55.7048...  \n",
       "2  [[-57.897354, -57.897354, -51.308334, -54.8423...  \n",
       "3  [[-59.127876, -59.127876, -55.668625, -55.1438...  \n",
       "4  [[-50.631554, -50.631554, -50.631554, -50.6315...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# путь к обработанным данным\n",
    "data_path = '../Module1/Dataset/dataset.h5'\n",
    "# загружаем датасета\n",
    "df = pd.read_hdf(data_path, key='df')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Класс с датасетом**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс для датасета\n",
    "class TTSDataset(Dataset):\n",
    "    # конструктор класса\n",
    "    def __init__(self, data_path):\n",
    "        '''data_path - путь к данным в формате h5'''\n",
    "        # получаем датафрейм\n",
    "        self.data = pd.read_hdf(data_path, key='df')\n",
    "        # получаем списки с токенами и мел-спектрограммами\n",
    "        self.mels = self.data['mel_spec']\n",
    "        self.token_ids = self.data['token_ids']\n",
    "\n",
    "    # метод для получения длины датасета\n",
    "    def __len__(self):\n",
    "        return len(self.token_ids)\n",
    "    \n",
    "    # метод получения элемента\n",
    "    def __getitem__(self, idx):\n",
    "        # возвращаем тензоры\n",
    "        token_ids = torch.LongTensor(self.token_ids[idx])\n",
    "        mel = torch.FloatTensor(self.mels[idx])\n",
    "\n",
    "        return token_ids, mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([25,  8, 25,  4,  3,  8,  5, 13,  3, 15, 10,  3, 11,  2, 13,  0, 12,  2,\n",
       "          3, 11, 25, 13, 25, 15, 11, 13,  9, 19,  5, 26,  3, 32,  2, 14, 11,  2,\n",
       "         26,  3, 15,  2,  3,  9,  3, 23, 29, 10, 15,  5, 26, 34, 34, 34, 34, 34,\n",
       "         34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
       "         34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
       "         34, 34, 34, 34, 34, 34, 34, 34, 34]),\n",
       " tensor([[-56.1889, -54.5283, -43.8420,  ..., -80.0000, -80.0000, -80.0000],\n",
       "         [-56.1889, -52.8671, -39.4327,  ..., -80.0000, -80.0000, -80.0000],\n",
       "         [-56.1889, -52.7999, -34.5382,  ..., -80.0000, -80.0000, -80.0000],\n",
       "         ...,\n",
       "         [-56.1889, -56.1889, -56.1889,  ..., -80.0000, -80.0000, -80.0000],\n",
       "         [-56.1889, -56.1889, -56.1889,  ..., -80.0000, -80.0000, -80.0000],\n",
       "         [-56.1889, -56.1889, -56.1889,  ..., -80.0000, -80.0000, -80.0000]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TTSDataset(data_path)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример 0:\n",
      "Токены: tensor([25,  8, 25,  4,  3,  8,  5, 13,  3, 15, 10,  3, 11,  2, 13,  0, 12,  2,\n",
      "         3, 11, 25, 13, 25, 15, 11, 13,  9, 19,  5, 26,  3, 32,  2, 14, 11,  2,\n",
      "        26,  3, 15,  2,  3,  9,  3, 23, 29, 10, 15,  5, 26, 34, 34, 34, 34, 34,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34,\n",
      "        34, 34, 34, 34, 34, 34, 34, 34, 34]) (длина: 99)\n",
      "Спектрограмма: torch.Size([80, 498])\n"
     ]
    }
   ],
   "source": [
    "# Проверяем один пример\n",
    "tokens, mel = dataset[0]\n",
    "print(\"Пример 0:\")\n",
    "print(f\"Токены: {tokens} (длина: {len(tokens)})\")\n",
    "print(f\"Спектрограмма: {mel.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Батч 0:\n",
      "Токены: torch.Size([16, 99])\n",
      "Спектрограммы: torch.Size([16, 80, 498])\n"
     ]
    }
   ],
   "source": [
    "# Проверяем батч\n",
    "for batch_idx, (tokens_batch, mels_batch) in enumerate(dataloader):\n",
    "    print(f\"\\nБатч {batch_idx}:\")\n",
    "    print(f\"Токены: {tokens_batch.shape}\")\n",
    "    print(f\"Спектрограммы: {mels_batch.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/Chemp/Speech-synthesis/Module2\n",
      "vocab_size: 35\n"
     ]
    }
   ],
   "source": [
    "# Параметры\n",
    "tokenizer = Tokenizer()\n",
    "vocab_size = tokenizer.getlen()      # пример размера словаря\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "n_mels = 80           # число мел-коэффициентов\n",
    "T_text = 99           # длина текстовой последовательности\n",
    "T_mel = 498           # временная длина мел-спектрограммы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Класс с моделью**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Text Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=256, hidden_dim=512):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=34)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(embed_dim, hidden_dim, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        # print('TE x1:', x.shape)\n",
    "        x = x.transpose(1,2)\n",
    "        # print('TE x2:', x.shape)\n",
    "        x = self.conv(x)\n",
    "        # print('TE x3:', x.shape)\n",
    "        x = x.transpose(1,2)\n",
    "        # print('TE x4:', x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_dim=512, mel_dim=80, seq_len=498):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, mel_dim)\n",
    "        )\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, hidden):\n",
    "        # hidden: (B, T, H)\n",
    "        x = self.linear(hidden)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        if x.size(2) < self.seq_len:\n",
    "            pad_amt = self.seq_len - x.size(2)\n",
    "            x = F.pad(x, (0, pad_amt), value=-80)\n",
    "        elif x.size(2) > self.seq_len:\n",
    "            x = x[:, :, :self.seq_len]\n",
    "\n",
    "        return x # (B, 80, 498)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VITS(nn.Module):\n",
    "    def __init__(self, vocab_size, pad_id=34):\n",
    "        super().__init__()\n",
    "        self.encoder = TextEncoder(vocab_size)\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        hidden = self.encoder(token_ids)\n",
    "        mel_pred = self.decoder(hidden)\n",
    "        return mel_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VITS(\n",
       "  (encoder): TextEncoder(\n",
       "    (embedding): Embedding(35, 256, padding_idx=34)\n",
       "    (conv): Sequential(\n",
       "      (0): Conv1d(256, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      (1): ReLU()\n",
       "      (2): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=80, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VITS(35)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1|10: 100%|██████████| 147/147 [00:01<00:00, 104.49it/s, loss=626]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1092.5527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2|10: 100%|██████████| 147/147 [00:01<00:00, 104.75it/s, loss=1.34e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1046.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3|10: 100%|██████████| 147/147 [00:01<00:00, 106.08it/s, loss=1.56e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1046.7510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4|10: 100%|██████████| 147/147 [00:01<00:00, 116.63it/s, loss=834]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1042.5812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5|10: 100%|██████████| 147/147 [00:01<00:00, 111.02it/s, loss=517]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1038.0670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6|10: 100%|██████████| 147/147 [00:01<00:00, 103.31it/s, loss=575]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 1039.2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7|10: 100%|██████████| 147/147 [00:01<00:00, 105.47it/s, loss=391]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1036.7770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8|10: 100%|██████████| 147/147 [00:01<00:00, 101.50it/s, loss=860]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 1040.0383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9|10: 100%|██████████| 147/147 [00:01<00:00, 106.90it/s, loss=1.16e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1041.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10|10: 100%|██████████| 147/147 [00:01<00:00, 107.22it/s, loss=810]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1038.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch+1}|{EPOCHS}')\n",
    "\n",
    "    for token_ids, mel_target in pbar:\n",
    "        token_ids, mel_target = token_ids.to(device), mel_target.to(device)\n",
    "\n",
    "        # прямой проход\n",
    "        mel_pred = model(token_ids)\n",
    "        # print(mel_pred.shape)\n",
    "        # print(mel_target.shape)\n",
    "\n",
    "        # потеря\n",
    "        loss = criterion(mel_pred, mel_target)\n",
    "\n",
    "        # обратный проход\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(dataloader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
